{
 "metadata": {
  "name": "",
  "signature": "sha256:7b60911c58c5a5129ba0ef3108966140fce903334e3e29e8613c72bfa205d303"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Model Objective Function"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model objective function casts the inverse problem as an optimization problem. The incorporation of prior information is related to the structural characteristics of the model. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$$\n",
      "\\phi = \\phi_d + \\beta \\phi_m\n",
      "$$\n",
      "For the linear problem we are considering\n",
      "$$\n",
      "\\phi_d = \\frac{1}{2}\\| W_d (Gm-d^{obs})\\|_2^2 = \\frac{1}{2}(Gm-d^{obs})^T W_d^T W_d (Gm-d^{obs})\n",
      "$$\n",
      "and\n",
      "$$\n",
      "\\phi_m = \\frac{1}{2} \\|W_m (m-m_{ref}) \\|^2_2 = \\frac{1}{2}(m-m_{ref})^T W_m^T W_m (m-m_{ref})\n",
      "$$\n",
      "\n",
      "To simplify the terms and see the math a little more clearly, let's note that $W_d(Gm-d^{obs})$, and $\\beta W_m(m-m_{ref})$ are simply vectors. And since we are taking the square of the 2-norm, all that we are really doing is taking the dot product of each vector with itself. So let $z=W_d(Gm-d^{obs})$, and let $y=W_m(m-m_{ref})$ where both $z$ and $y$ vectors are functions of $m$. So then:\n",
      "\n",
      "$$\n",
      "\\phi_d =  \\frac{1}{2}\\|z\\|_2^2 = \\frac{1}{2}z^T z = \\frac{1}{2}(W_d(Gm-d^{obs}))^T W_d(Gm-d^{obs}) = \\frac{1}{2} (Gm-d^{obs})^T W_d^T W_d (Gm-d^{obs})\n",
      "$$<br>\n",
      "$$\n",
      "\\phi_m =  \\frac{1}{2}\\|y\\|_2^2 =\\frac{1}{2}y^T y = \\frac{1}{2}(W_m (m-m_{ref}))^T W_m (m-m_{ref}) = \\frac{1}{2} (m-m_{ref})^T W_m^T W_m (m-m_{ref})\n",
      "$$\n",
      "\n",
      "\n",
      "To minimize this, we want to look at $\\nabla \\phi$ $\\nabla \\nabla \\phi$. Using our compact expressions for our vectors:\n",
      "$$\n",
      "\\phi = \\phi_d + \\beta \\phi_m = \\frac{1}{2}z^Tz + \\beta \\frac{1}{2}y^Ty \\\\ \n",
      "$$\n",
      "\n",
      "Taking the derivative with respect to $m$ yields:\n",
      "$$\n",
      "\\frac{d \\phi}{dm} = \\frac{1}{2}  \\left(z^T \\frac{dz}{dm} +  z^T \\frac{dz}{dm} + y^T \\frac{dy}{dm} + y^T \\frac{dy}{dm}\\right) = z^T \\frac{dz}{dm} + y^T \\frac{dy}{dm}\n",
      "$$\n",
      "\n",
      "Note that \n",
      "$$\\frac{d \\phi_d}{dm} = \\frac{d}{dm}(W_d(Gm-d^{obs})) = W_d G $$ \n",
      "\n",
      "and \n",
      "\n",
      "$$ \\frac{d \\phi_m}{dm} = \\frac{d}{dm}(W_m (m-m_{ref})) = W_m $$\n",
      "Next, let's substitute back what we had for both $z$ and $y$:<br>\n",
      "\\begin{equation}\n",
      "\\begin{split}\n",
      "\\frac{d \\phi}{dm} & = z^T \\frac{dz}{dm} + y^T \\frac{dy}{dm} \\\\[0.6em]\n",
      " & = (W_d(Gm-d^{obs}))^T W_d G + \\beta (W_m (m-m_{ref}))^T W_m\\\\[0.6em]\n",
      " & = (Gm-d^{obs})^T W_d^T W_d G + \\beta (m-m_{ref})^T W_m^T W_m \\\\[0.6em]\n",
      " & = ((Gm)^T - d^T) W_d^T W_d G + \\beta (m^T-m_{ref}^T)W_m^T W_m \\\\[0.6em]\n",
      " & = (m^T G^T - d^T) W_d^T W_d G + \\beta m^T W_m^T W_m - \\beta  m_{ref}^T W_m^T W_m \\\\[0.6em]\n",
      " & = m^T G^T W_d^T W_d G  - d^T W_d^T W_d G + \\beta m^T W_m^T W_m - \\beta  m_{ref}^T W_m^T W_m\\\\[0.6em]\n",
      " & = m^T G^T W_d^T W_d G  + \\beta m^T W_m^T W_m - d^T W_d^T W_d G - \\beta  m_{ref}^T W_m^T W_m\\\\[0.6em]\n",
      " \\end{split}\n",
      "\\end{equation}\n",
      "\n",
      "Now we have an expression for the derivative of our equation that we can work with. Setting the gradient to zero and gathering like terms gives:<br>\n",
      "\n",
      "\\begin{equation} \n",
      "\\begin{split}\n",
      " m^T G^T W_d^T W_d G  + \\beta m^T W_m^T W_m = d^T W_d^T W_d G + \\beta  m_{ref}^T W_m^T W_m\\\\[0.6em]\n",
      " (G^T W_d^T W_d G  + \\beta W_m^T W_m)m = G^T W_d^T W_d d + \\beta  W_m^T W_m m_{ref}\\\\[0.6em]\n",
      "\\end{split}\n",
      "\\end{equation}\n",
      "\n",
      "From here we can do two things. First, we can solve for $m$, our recovered model:\n",
      "\n",
      "\\begin{equation}\n",
      "\\begin{split}\n",
      " m = (G^T W_d^T W_d G  + \\beta W_m^T W_m)^{-1} (G^T W_d^T W_d d + \\beta  W_m^T W_m m_{ref})\\\\[0.6em]\n",
      "\\end{split}\n",
      "\\end{equation}\n",
      "\n",
      "Second, we can get the second derivative simply from the bracketed terms in the left hand side of the equation above:\n",
      "\\begin{equation} \n",
      "\\frac{d^2 \\phi}{dm^2} = G^T W_d^T W_d G  + \\beta W_m^T W_m\n",
      "\\end{equation}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}